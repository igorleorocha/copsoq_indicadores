# -*- coding: utf-8 -*-
"""COPSOQ_indicadores_validacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O_W4OPGVrxb5eeE7OiQzePqu5q85cX9L
"""

# 1. Instalação da biblioteca de estatística
!pip install factor_analyzer

# 2. Importação de bibliotecas e ferramentas de upload
import pandas as pd
import numpy as np
import os
from google.colab import files, drive
from factor_analyzer import FactorAnalyzer

# 3. Upload do arquivo de mapeamento
print("Por favor, selecione o arquivo: 'associado_indicadores.xlsx '")
uploaded = files.upload()

# Identifica o nome do arquivo carregado para evitar erros de digitação
nome_real_arquivo = list(uploaded.keys())[0]
mapping = pd.read_csv(nome_real_arquivo)

print(f"\nSucesso! Arquivo '{nome_real_arquivo}' carregado e lido.")

# CONFIGURAÇÕES DE REPRODUTIBILIDADE
SEED = 42
np.random.seed(SEED)
N_AMOSTRA = 500

# GERAÇÃO DA BASE SIMULADA (TOY DATASET)
# Simula a estrutura latente para os 3 indicadores conforme a proposta metodológica [cite: 69, 70]
latent_factors = np.random.multivariate_normal(
    mean=[0, 0, 0],
    cov=[[1.0, 0.2, 0.2], [0.2, 1.0, 0.2], [0.2, 0.2, 1.0]],
    size=N_AMOSTRA
)

df_simulada = pd.DataFrame()
for idx, row in mapping.iterrows():
    item_id = f"Item_{row['Nº']}"
    f_idx = 0 if 'ISP' in row['Indicador'] else (1 if 'IAT' in row['Indicador'] else 2)

    # Gera dados com carga fatorial baseada na teoria dos macro-fatores [cite: 103, 106]
    raw = 0.7 * latent_factors[:, f_idx] + np.random.normal(0, 0.5, N_AMOSTRA)

    # Discretização para escala Likert 1-5 conforme as diretrizes do instrumento [cite: 67]
    scaled = (raw - raw.min()) / (raw.max() - raw.min())
    df_simulada[item_id] = np.round(scaled * 4 + 1).astype(int)

# ANÁLISE ESTATÍSTICA
fa = FactorAnalyzer(n_factors=3, method='principal', rotation='varimax')
fa.fit(df_simulada)

def calcular_alfa(df, indicador_nome):
    itens = mapping[mapping['Indicador'].str.contains(indicador_nome)]['Nº']
    cols = [f"Item_{i}" for i in itens]
    sub_df = df[cols]
    k = sub_df.shape[1]
    item_vars = sub_df.var(ddof=1).sum()
    total_var = sub_df.sum(axis=1).var(ddof=1)
    return (k / (k - 1)) * (1 - (item_vars / total_var))

# Resultados Finais
print("\n--- RESULTADOS DA VALIDAÇÃO (N=500) ---")
print(f"Alfa de Cronbach - ISP: {calcular_alfa(df_simulada, 'ISP'):.3f}")
print(f"Alfa de Cronbach - IAT: {calcular_alfa(df_simulada, 'IAT'):.3f}")
print(f"Alfa de Cronbach - NSP: {calcular_alfa(df_simulada, 'NSP'):.3f}")

# DOWNLOAD
nome_arquivo = 'base_simulada_500_respostas.csv'
df_simulada.to_csv(nome_arquivo, index=False)

from google.colab import files
print(f"\nProcessamento concluído. Iniciando download de: {nome_arquivo}")
files.download(nome_arquivo)